---
title: "dada2_pipeline"
author: "Vincent Caruso"
date: "July 20, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Setup

First, load required libraries.
```{r libraries}

library("dada2")
library("stringr")
library("Biostrings")
library("ggplot2")

```

Next, set the working directory and file paths.
```{r paths}

data_path <- "~/projects/thesis/data"
result_path <- "~/projects/thesis/results"
raw_path <- file.path(data_path, "raw")
filt_path <- file.path(data_path, "filtered")
ref_path <- file.path(data_path, "reference")
dada2_path <- file.path(result_path, "dada2")
setwd(data_path)

#load(file.path(dada2_path, "dadas.RData"))

```

The file names are really long and contain redundant information, so I'll rename them to remove the unnecessary bits.
```{r rename files}

# file_names <- list.files(raw_path)
# fastqs <- str_subset(file_names, ".fastq$")

# rename files in MockCommunities folder

# for (i in seq_along(fastqs)){
#   new_name <- fastqs[i]
#   new_name <- str_replace(new_name, "lane1-", "")
#   new_name <- str_replace(new_name, "index-[ACGT]+-", "")
#   new_name <- str_replace(new_name, "_S\\d{3}_L001", "")
#   new_name <- str_replace(new_name, "_001", "")
#   file.rename(fastqs[i], new_name)
# }

```


##Filtering and Trimming

First, I want to look at the quality profiles of forward and reverse reads separately.
```{r plot qualities}

file_names <- list.files(raw_path)
fastqs <- str_subset(file_names, ".fastq$")
fastq_Fs <- str_subset(fastqs, "_R1")
fastq_Rs <- str_subset(fastqs, "_R2")

#get the sample names
sample_names <- sapply(str_split(fastq_Fs, "_R\\d"), `[`, 1)

# plot quality
plotQualityProfile(file.path(raw_path, fastq_Fs[1])) + 
  scale_y_continuous(limits = c(10, 40), breaks = seq(10, 40, 5)) +
  scale_x_continuous(limits = c(0, 250), breaks = seq(0, 250, 10)) +
  theme(panel.grid.major = element_line(colour="grey", size=0.5)) +
  ggtitle(str_replace(fastq_Fs[1], ".fastq", ""))
plotQualityProfile(file.path(raw_path, fastq_Rs[1])) + 
  scale_y_continuous(limits = c(10, 40), breaks = seq(10, 40, 5)) +
  scale_x_continuous(limits = c(0, 250), breaks = seq(0, 250, 10)) +
  theme(panel.grid.major = element_line(colour="grey", size=0.5)) +
  ggtitle(str_replace(fastq_Rs[1], ".fastq", ""))


```

The quality isn't great for most of the read sets. For the "Neat" sample, I'll trim the forward reads at position 230 for now, and the reverse reads at position 210. I'm also trimming the first 10 nucleotides-- the Illumina "burn-in".
```{r filter}

#Set up a directory and file names for the filtered reads
if (!file_test("-d", filt_path)) dir.create(filt_path)
filt_Fs <- paste0(sample_names, "_F_filt.fastq")
filt_Rs <- paste0(sample_names, "_R_filt.fastq")

#Filter paired read sets
for (i in seq_along(fastq_Fs)){
  fastqPairedFilter(file.path(raw_path, c(fastq_Fs[i], fastq_Rs[i])), file.path(filt_path, c(filt_Fs[i], filt_Rs[i])), 
                    truncLen = c(230, 210), trimLeft = c(10,10),
                    maxN = 0, maxEE = c(3,4), truncQ = 2, rm.phix = TRUE,
                    compress = FALSE, verbose = TRUE)
}

```


##Dereplication

Collapse sequence replicates into single sequences, each with a summary of the quality scores at each base position.
```{r dereplicate}

derep_Fs <- derepFastq(file.path(filt_path, filt_Fs), verbose = TRUE)
derep_Rs <- derepFastq(file.path(filt_path, filt_Rs), verbose = TRUE)

names(derep_Fs) <- sample_names
names(derep_Rs) <- sample_names

```


##Error parameter estimation

Learn the error rates from the data.
```{r errors}

dada_Fs.lrn <- dada(derep_Fs, err = NULL, selfConsist = TRUE, multithread = TRUE)
dada_Rs.lrn <- dada(derep_Rs, err = NULL, selfConsist = TRUE, multithread = TRUE)

err_Fs <- dada_Fs.lrn[[1]]$err_out
err_Rs <- dada_Rs.lrn[[1]]$err_out

```

Let's take a look at the learned errors.
```{r plot errors}

plotErrors(dada_Fs.lrn[[1]], nominalQ = TRUE)
plotErrors(dada_Rs.lrn[[1]], nominalQ = TRUE)


```

Since I used all the read data to learn the error rates, the sequence inference for all samples has already been done by DADA2. However, I'll do the inference again formally here, for consistency, using the learned error rates.
```{r SV inference}

dada_Fs <- dada(derep_Fs, err = err_Fs, multithread = TRUE)
dada_Rs <- dada(derep_Rs, err = err_Rs, multithread = TRUE)

dada_Fs[[10]]
dada_Rs[[10]]

# Save the dada objects
save(derep_Fs, derep_Rs, dada_Fs.lrn, dada_Rs.lrn, dada_Fs, dada_Rs, file = file.path(dada2_path, "dada2.RData"))

```


##Merging of paired reads

Like it says, now I'm going to merge the paired reads. This will reduce the number of spurious sequences.
```{r merge SVs}

merged <- mergePairs(dada_Fs, derep_Fs, dada_Rs, derep_Rs, maxMismatch = 0, 
                     propagateCol = c("n0", "n1", "birth_fold", "birth_ham"), 
                     verbose = TRUE)

head(merged[[1]])

```


##Create a sequence table

This converts the inferred sequence data into a table, similar to an OTU table.
```{r sequence table}

sv_table <- makeSequenceTable(merged)
dim(sv_table)

table(nchar(getSequences(sv_table)))

```

If there are any sequences with lengths outside the expected range for the V4 region, I want to remove those.
```{r remove bad lengths}

# min_len <- 230
# max_len <- 235
# sv_table.good <- sv_table[, nchar(getSequences(sv_table)) %in% seq(min_len, max_len)]
# 
# table(nchar(getSequences(sv_table.253)))


```


##Remove chimeras

DADA2 only considers "bimeras", or chimeras spawned from exactly two parents sequences.
```{r remove chimeras}

sv_table.no_chim <- removeBimeraDenovo(sv_table, verbose = TRUE)
dim(sv_table.no_chim)

#check what percentage of reads remain
sum(sv_table.no_chim) / sum(sv_table)

#how many sequence variants are in each sample?
rowSums(sv_table.no_chim > 0)

```


##Assign taxonomy
```{r taxonomy}

taxa <- assignTaxonomy(sv_table.no_chim, file.path(ref_path, "silva_nr_v123_train_set.fa.gz"))
genus.species <- assignSpecies(sv_table.no_chim, file.path(ref_path, "silva_species_assignment_v123.fa.gz"))

# save tables
save(merged, sv_table, sv_table.no_chim, taxa, genus.species, file = file.path(dada2_path, "tables.RData"))

```


##Get reference sequences and create a reference database in fasta format

```{r create reference database}

#ref_path <- "C:/Users/vinny/Box Sync/OHSU/Research/Thesis project/Projects/Miseq316/ZymoBIOMICS.STD.genomes.ZR160406/BioPool_genomes/16S-18S"

# ref_names <- list.files(ref_path)
# 
# ref_seqs <- list(0)
# for (i in seq_along(ref_names)){
#   ref_seqs[[i]] <- readFasta(file.path(ref_path, ref_names[i]))
# }

```